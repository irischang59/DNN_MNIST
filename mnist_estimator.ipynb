{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from datetime import datetime\n",
    "\n",
    "# He et al. initialization from https://arxiv.org/abs/1502.01852\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "# This class inherits from Sklearn's BaseEstimator and ClassifierMixin \n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, \n",
    "                 optimizer_class=tf.train.AdamOptimizer, \n",
    "                 learning_rate=0.01, batch_size=64, \n",
    "                 activation=tf.nn.elu, initializer=he_init, \n",
    "                 batch_norm_momentum=None, dropout_rate=None, \n",
    "                 max_checks_without_progress=20, show_progress=10, \n",
    "                 tensorboard_logdir=None, random_state=None):\n",
    "\n",
    "        # Initialize the class with sensible default hyperparameters\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_checks_without_progress = max_checks_without_progress\n",
    "        self.show_progress = show_progress\n",
    "        self.random_state = random_state\n",
    "        self.tensorboard_logdir = tensorboard_logdir\n",
    "        self._session = None # Instance variables preceded by _ are private members\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        '''This method builds the hidden layers and \n",
    "        Provides for implementation of batch normalization and dropout'''\n",
    "\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "\n",
    "            # Apply dropout if specified\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, rate=self.dropout_rate, training=self._training)\n",
    "            # Create the hidden layer\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons, \n",
    "                                     activation=self.activation, \n",
    "                                     kernel_initializer=self.initializer, \n",
    "                                     name = \"hidden{}\".format(layer+1))\n",
    "\n",
    "            # Apply batch normalization if specified\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs,momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "\n",
    "            # Apply activation function\n",
    "            inputs = self.activation(inputs, name=\"hidden{}_out\".format(layer+1))\n",
    "        return inputs\n",
    "\n",
    "    def _construct_graph(self, n_inputs, n_outputs):\n",
    "        '''This method builds the complete Tensorflow computation graph\n",
    "        n_inputs: number of features \n",
    "        n_outputs: number of classes\n",
    "        '''\n",
    "\n",
    "        if self.random_state:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    " \n",
    "        # Placeholders for training data, labels are class exclusive integers\n",
    "        X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "        \n",
    "        # Create a training placeholder \n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        # Output after hidden layers \n",
    "        pre_output = self._dnn(X)\n",
    "        \n",
    "        # Outputs from output layer\n",
    "        logits = tf.layers.dense(pre_output, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        probabilities = tf.nn.softmax(logits, name=\"probabilities\")\n",
    "        \n",
    "        ''' Cost function is cross entropy and loss is average cross entropy. Sparse softmax must be used because shape of logits is [None, n_classes] and shape of labels is [None]'''\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        '''Optimizer and training operation. The control dependency is necessary for implementing batch normalization. The training operation must be dependent on the batch normalization.'''\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            training_op = optimizer.minimize(loss)\n",
    "\n",
    "        # Metrics for evaluation\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)    \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32),name=\"accuracy\")\n",
    "\n",
    "        # Initializer and saver \n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        if self.tensorboard_logdir:\n",
    "            now = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "            tb_logdir = self.tensorboard_logdir + \"/run-{}\".format(now)\n",
    "            cost_summary = tf.summary.scalar(\"validation_loss\", loss)\n",
    "            acc_summary = tf.summary.scalar(\"validation_accuracy\", accuracy)\n",
    "            merged_summary = tf.summary.merge_all()\n",
    "            file_writer = tf.summary.FileWriter(tb_logdir, tf.get_default_graph())\n",
    "\n",
    "            self._merged_summary = merged_summary\n",
    "            self._file_writer = file_writer\n",
    "\n",
    "        self._X, self._y = X, y\n",
    "        self._logits = logits\n",
    "        self._probabilities = probabilities\n",
    "        self._loss = loss\n",
    "        self._training_op = training_op\n",
    "        self._accuracy = accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "        \n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_parameters(self):\n",
    "        # Retrieves the value of all the variables in the network \n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in \n",
    "                zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_parameters(self, model_params):\n",
    "        # Restores the value of all variables using tf assign operations\n",
    "        # First retrieve the list of all the graph variables\n",
    "        gvar_names = list(model_params.keys())\n",
    "\n",
    "        # Then retrieve all the assignment operations in the graph\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name +  \"/Assign\") for gvar_name in gvar_names}\n",
    "\n",
    "        # Fetch the initialization values of the assignment operations\n",
    "        '''graph.get_operation_by_name(operation).inputs returns the input to the given operation; because these are all assignment operations, the second argument to inputs is the value assigned to the variable'''\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op \t\t\t  in assign_ops.items()}\n",
    "        # Create a dictionary mapping initial values to values after training\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        # Assign the trained value to all the variables in the graph\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        # Method to train the model. Implements early stopping if validation data is provided \n",
    "\n",
    "        self.close_session()\n",
    "        n_inputs = X.shape[1] # Number of features\n",
    "\n",
    "        # If labels are provided in one_hot form, convert to integer class labels\n",
    "        y = np.array(y)\n",
    "        y_valid = np.array(y_valid)\n",
    "\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    " \n",
    "        if len(y_valid.shape) == 2:\n",
    "            y_valid = np.argmax(y_valid, axis=1)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_) # Number of classes\n",
    "\n",
    "        # Tensorflow expects labels from 0 to n_classes - 1. \n",
    "        self.class_to_index_ = {label: index for index, label in enumerate(self.classes_)}\n",
    "        labels = [self.class_to_index_[label] for label in y]\n",
    "        y = np.array(labels, dtype=np.int32)\n",
    "\n",
    "        self._graph = tf.Graph()\n",
    "\n",
    "        # Build the computation graph with self as default graph\n",
    "        with self._graph.as_default():\n",
    "            self._construct_graph(n_inputs, n_outputs)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        checks_without_progress = 0 \n",
    "        best_loss = np.float(\"inf\")\n",
    "        best_parameters = None\n",
    "        \n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "\n",
    "        with self._session.as_default() as sess:\n",
    "            # Initialize all variables\n",
    "            self._init.run()\n",
    "            num_instances = X.shape[0] # Total number of training instances\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(num_instances)\n",
    "                for rnd_indices in np.array_split(rnd_idx, num_instances // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    train_acc, _ = sess.run([self._accuracy,self._training_op], feed_dict)\n",
    "\n",
    "                # Early stopping implementation\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    feed_dict_valid = {self._X: X_valid, self._y: y_valid}\n",
    "\n",
    "                    # Write summary for tensorboard\n",
    "                    if self.tensorboard_logdir:\n",
    "                        val_acc, val_loss, summary = sess.run([self._accuracy, self._loss, self._merged_summary], feed_dict=feed_dict_valid)\n",
    "\n",
    "                        self._file_writer.add_summary(summary, epoch)\n",
    "\n",
    "                    else:\n",
    "                        val_acc, val_loss = sess.run([self._accuracy, self._loss], feed_dict=feed_dict_valid)\n",
    "\n",
    "                    # Show training progress every show_progress epochs\n",
    "                    if self.show_progress:\n",
    "                        if epoch % self.show_progress == 0:\n",
    "                            print(\"Epoch: {} Current training accuracy: {:.4f} Validation Accuracy: {:.4f} Validation Loss {:.6f}\".format(\n",
    "                                epoch+1, train_acc, val_acc, val_loss))\n",
    "\n",
    "                    # Check to see if model is improving \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        checks_without_progress = 0\n",
    "                        best_parameters = self._get_model_parameters()\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "\n",
    "                    if checks_without_progress > self.max_checks_without_progress:\n",
    "                        print(\"Stopping Early! Loss has not improved in {} epochs\".format(self.max_checks_without_progress))\n",
    "                        break\n",
    "   \n",
    "                # No validation set provided\n",
    "                else:\n",
    "                    if self.show_progress:\n",
    "                        if epoch % self.show_progress == 0:\n",
    "                            print(\"Epoch: {} Current training accuracy: {:.4f}\".format(epoch+1, train_acc))\n",
    "\n",
    "            # In the case of early stopping, restore the best weight values\n",
    "            if best_parameters:\n",
    "                self._restore_model_parameters(best_parameters)\n",
    "                return self\n",
    "\n",
    "    def predict_probabilities(self, X):\n",
    "        # Predict the probabilities of each class \n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._probabilities.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the classes themselves and return with shape=(None,)\n",
    "        class_indices = np.argmax(self.predict_probabilities(X), axis=1)\n",
    "        predictions = np.array([[self.classes_[class_index]] for class_index in class_indices], dtype=np.int32)\n",
    "        return np.reshape(predictions, (-1,))\n",
    "\n",
    "    def save(self, path):\n",
    "        # Save the model to provided path\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\")\n",
    "\n",
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_validation = mnist.validation.images\n",
    "y_validation = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Current training accuracy: 0.9375 Validation Accuracy: 0.9490 Validation Loss 0.197036\n",
      "Epoch: 11 Current training accuracy: 0.9219 Validation Accuracy: 0.9626 Validation Loss 0.217349\n",
      "Epoch: 21 Current training accuracy: 0.9531 Validation Accuracy: 0.9412 Validation Loss 0.312047\n",
      "Stopping Early! Loss has not improved in 20 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x11861a5f0>,\n",
       "       batch_norm_momentum=None, batch_size=64, dropout_rate=None,\n",
       "       initializer=<function _initializer at 0xf20bc9140>,\n",
       "       learning_rate=0.01, max_checks_without_progress=20,\n",
       "       n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42, show_progress=10,\n",
       "       tensorboard_logdir='tensorboard_stats')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = DNNClassifier(tensorboard_logdir=\"tensorboard_stats\", random_state=42)\n",
    "dnn.fit(X_train, y_train, 100, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 95.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn.predict(X_test)\n",
    "print(\"Accuracy on the test set: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHVCAYAAABSR+pHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Confidence: 0.00%\n",
      "1 Confidence: 100.00%\n",
      "2 Confidence: 0.00%\n",
      "3 Confidence: 0.00%\n",
      "4 Confidence: 0.00%\n",
      "5 Confidence: 0.00%\n",
      "6 Confidence: 0.00%\n",
      "7 Confidence: 0.00%\n",
      "8 Confidence: 0.00%\n",
      "9 Confidence: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHVCAYAAABSR+pHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wcd0QPsb+SHZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Confidence: 0.01%\n",
      "1 Confidence: 0.16%\n",
      "2 Confidence: 98.81%\n",
      "3 Confidence: 0.11%\n",
      "4 Confidence: 0.05%\n",
      "5 Confidence: 0.00%\n",
      "6 Confidence: 0.00%\n",
      "7 Confidence: 0.01%\n",
      "8 Confidence: 0.84%\n",
      "9 Confidence: 0.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHVCAYAAABSR+pHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naCCwANBAYAGggcACQIP/AbBhj9wRXR4UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Confidence: 0.05%\n",
      "1 Confidence: 90.36%\n",
      "2 Confidence: 1.56%\n",
      "3 Confidence: 0.22%\n",
      "4 Confidence: 1.02%\n",
      "5 Confidence: 0.15%\n",
      "6 Confidence: 2.15%\n",
      "7 Confidence: 0.61%\n",
      "8 Confidence: 3.65%\n",
      "9 Confidence: 0.24%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAHVCAYAAABSR+pHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTAgFTORyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Confidence: 0.00%\n",
      "1 Confidence: 0.00%\n",
      "2 Confidence: 0.02%\n",
      "3 Confidence: 0.00%\n",
      "4 Confidence: 0.00%\n",
      "5 Confidence: 0.00%\n",
      "6 Confidence: 0.00%\n",
      "7 Confidence: 99.97%\n",
      "8 Confidence: 0.00%\n",
      "9 Confidence: 0.00%\n"
     ]
    }
   ],
   "source": [
    "example_indices = np.random.randint(len(X_test), size=4)\n",
    "\n",
    "for i, image_index in enumerate(example_indices):\n",
    "    probabilities = dnn.predict_probabilities(X_test[image_index].reshape(-1, 784))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(X_test[image_index].reshape(28,28), cmap=\"binary\")\n",
    "    plt.show()\n",
    "    for label, probability in zip(dnn.classes_, probabilities[0]):\n",
    "        print(\"{} Confidence: {:.2f}%\".format(label, probability*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Randomized Search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=0.5 ...............\n",
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=0.5, total= 3.0min\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=0.5 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=0.5, total= 3.0min\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=0.5 ...............\n",
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=0.5, total= 3.0min\n",
      "[CV] n_hidden_layers=4, n_neurons=50, dropout_rate=0.5 ...............\n",
      "[CV]  n_hidden_layers=4, n_neurons=50, dropout_rate=0.5, total= 2.7min\n",
      "[CV] n_hidden_layers=4, n_neurons=50, dropout_rate=0.5 ...............\n",
      "[CV]  n_hidden_layers=4, n_neurons=50, dropout_rate=0.5, total= 2.7min\n",
      "[CV] n_hidden_layers=4, n_neurons=50, dropout_rate=0.5 ...............\n",
      "[CV]  n_hidden_layers=4, n_neurons=50, dropout_rate=0.5, total= 2.6min\n",
      "[CV] n_hidden_layers=5, n_neurons=100, dropout_rate=0.5 ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=100, dropout_rate=0.5, total= 4.0min\n",
      "[CV] n_hidden_layers=5, n_neurons=100, dropout_rate=0.5 ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=100, dropout_rate=0.5, total= 3.9min\n",
      "[CV] n_hidden_layers=5, n_neurons=100, dropout_rate=0.5 ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=100, dropout_rate=0.5, total= 4.2min\n",
      "[CV] n_hidden_layers=4, n_neurons=100, dropout_rate=None .............\n",
      "[CV]  n_hidden_layers=4, n_neurons=100, dropout_rate=None, total= 2.6min\n",
      "[CV] n_hidden_layers=4, n_neurons=100, dropout_rate=None .............\n",
      "[CV]  n_hidden_layers=4, n_neurons=100, dropout_rate=None, total= 2.6min\n",
      "[CV] n_hidden_layers=4, n_neurons=100, dropout_rate=None .............\n",
      "[CV]  n_hidden_layers=4, n_neurons=100, dropout_rate=None, total= 2.5min\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=None ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=None, total= 2.0min\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=None ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=None, total= 2.2min\n",
      "[CV] n_hidden_layers=5, n_neurons=50, dropout_rate=None ..............\n",
      "[CV]  n_hidden_layers=5, n_neurons=50, dropout_rate=None, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 42.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x11861a5f0>,\n",
       "       batch_norm_momentum=None, batch_size=64, dropout_rate=None,\n",
       "       initializer=<function _initializer at 0xf20bc9140>,\n",
       "       learning_rate=0.01, max_checks_without_progress=20,\n",
       "       n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42, show_progress=None, tensorboard_logdir=None),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=1,\n",
       "          param_distributions={'n_hidden_layers': [4, 5], 'n_neurons': [50, 100], 'dropout_rate': [None, 0.5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dnn = DNNClassifier(show_progress=None, random_state=42)\n",
    "\n",
    "parameter_distributions = {\n",
    "    'n_hidden_layers': [4, 5],\n",
    "    'n_neurons': [50, 100],\n",
    "    'dropout_rate': [None, 0.5]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(dnn, parameter_distributions, n_iter=5, scoring='accuracy', verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': None, 'n_hidden_layers': 4, 'n_neurons': 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 88.51%\n"
     ]
    }
   ],
   "source": [
    "best_mnist_dnn = random_search.best_estimator_\n",
    "mnist_predictions = best_mnist_dnn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_score(y_test, mnist_predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search.best_estimator_.save(\"models/mnist_random_best_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
